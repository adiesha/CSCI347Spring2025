{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a438a324-658c-46f1-95c7-317b07615946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>568454 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                      ProfileName  \\\n",
       "0            1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1            2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2            3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3            4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4            5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "...        ...         ...             ...                              ...   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY                 Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                        R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z                    pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH          Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                         srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                          1                       1      5  1303862400   \n",
       "1                          0                       0      1  1346976000   \n",
       "2                          1                       1      4  1219017600   \n",
       "3                          3                       3      2  1307923200   \n",
       "4                          0                       0      5  1350777600   \n",
       "...                      ...                     ...    ...         ...   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                   Summary  \\\n",
       "0                    Good Quality Dog Food   \n",
       "1                        Not as Advertised   \n",
       "2                    \"Delight\" says it all   \n",
       "3                           Cough Medicine   \n",
       "4                              Great taffy   \n",
       "...                                    ...   \n",
       "568449                 Will not do without   \n",
       "568450                        disappointed   \n",
       "568451            Perfect for our maltipoo   \n",
       "568452  Favorite Training and reward treat   \n",
       "568453                         Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "0       I have bought several of the Vitality canned d...  \n",
       "1       Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2       This is a confection that has been around a fe...  \n",
       "3       If you are looking for the secret ingredient i...  \n",
       "4       Great taffy at a great price.  There was a wid...  \n",
       "...                                                   ...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  \n",
       "\n",
       "[568454 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('./Reviews.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27516229-14f5-4759-9272-e5a9b7e318a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "920b87b2-ec79-4999-956b-77af83609f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df= df[['Text','Score']].sample(frac=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c470a9fd-4879-45fe-a408-8978a8ec2703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284227, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71ebb004-4a15-4076-922e-69bed2fb87e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>288312</th>\n",
       "      <td>I love the Cherry Pie Lara bar.  Best and tast...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431726</th>\n",
       "      <td>Melitta Cafe COllection Blanc et Noir coffee h...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110311</th>\n",
       "      <td>my girls absolutely loved this tuna. they were...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91855</th>\n",
       "      <td>The vendor is fast and dependable. The tea is ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338855</th>\n",
       "      <td>UPDATE - 8/9/2010&lt;br /&gt;A lot can happen in jus...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243608</th>\n",
       "      <td>I have pretty much tried them all. The dark ch...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152343</th>\n",
       "      <td>Just be forewarned it is a bit \"moist.\"  Have ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336202</th>\n",
       "      <td>Both of my mixed terrier dogs prefer this trea...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488611</th>\n",
       "      <td>Made this coffee with a percolator maybe that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103618</th>\n",
       "      <td>This was just the basic ingredients that i cou...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text  Score\n",
       "288312  I love the Cherry Pie Lara bar.  Best and tast...      5\n",
       "431726  Melitta Cafe COllection Blanc et Noir coffee h...      5\n",
       "110311  my girls absolutely loved this tuna. they were...      5\n",
       "91855   The vendor is fast and dependable. The tea is ...      5\n",
       "338855  UPDATE - 8/9/2010<br />A lot can happen in jus...      5\n",
       "243608  I have pretty much tried them all. The dark ch...      5\n",
       "152343  Just be forewarned it is a bit \"moist.\"  Have ...      5\n",
       "336202  Both of my mixed terrier dogs prefer this trea...      5\n",
       "488611  Made this coffee with a percolator maybe that ...      1\n",
       "103618  This was just the basic ingredients that i cou...      5"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcf5c784-25e3-4f4a-950d-51ac991de6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d090f33c-491c-4160-ab2c-0fe1eb44e1cd",
   "metadata": {},
   "source": [
    "**Let's see how we can convert a document into a bag of word**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff6ffc9a-daa3-410e-aaa2-fd609d4ee643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['about' 'another' 'content' 'despite' 'doc' 'document' 'excessive'\n",
      " 'fifth' 'information' 'is' 'length' 'much' 'one' 'provided' 'the' 'third'\n",
      " 'this' 'without' 'yet']\n",
      "['about' 'about the' 'about the content' 'another' 'another doc'\n",
      " 'another document' 'content' 'content despite' 'content despite the'\n",
      " 'despite' 'despite the' 'despite the excessive' 'doc' 'document'\n",
      " 'document without' 'document without much' 'excessive' 'excessive length'\n",
      " 'fifth' 'fifth one' 'information' 'information information'\n",
      " 'information information provided' 'information provided'\n",
      " 'information provided about' 'is' 'is another' 'is another document'\n",
      " 'is document' 'is the' 'is the fifth' 'is the third' 'is yet'\n",
      " 'is yet another' 'length' 'much' 'much information'\n",
      " 'much information information' 'one' 'provided' 'provided about'\n",
      " 'provided about the' 'the' 'the content' 'the content despite'\n",
      " 'the excessive' 'the excessive length' 'the fifth' 'the fifth one'\n",
      " 'the third' 'the third document' 'third' 'third document' 'this'\n",
      " 'this is' 'this is another' 'this is document' 'this is the'\n",
      " 'this is yet' 'without' 'without much' 'without much information' 'yet'\n",
      " 'yet another' 'yet another doc']\n",
      "[[0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 0 0]\n",
      " [0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 0 1 0 0]\n",
      " [1 0 1 1 0 1 1 0 2 0 1 1 0 1 2 0 0 1 0]]\n",
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.3348279  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.28915067 0.         0.         0.56438725 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.28915067\n",
      "  0.28915067 0.         0.56438725 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.34014611 0.         0.41480509\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.24608691 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21251573 0.41480509 0.41480509 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.21251573\n",
      "  0.21251573 0.41480509 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.21022844 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.18154908 0.         0.         0.         0.29058183\n",
      "  0.         0.35436191 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.24532915 0.         0.         0.         0.         0.\n",
      "  0.         0.35436191 0.35436191 0.35436191 0.35436191 0.18154908\n",
      "  0.18154908 0.         0.         0.29058183 0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.26661163 0.32513046 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.32513046 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.16657302 0.         0.         0.         0.\n",
      "  0.         0.         0.32513046 0.32513046 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.16657302\n",
      "  0.16657302 0.         0.         0.         0.32513046 0.\n",
      "  0.         0.         0.32513046 0.32513046 0.32513046]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.34076783 0.34076783 0.         0.         0.         0.\n",
      "  0.         0.17458447 0.         0.         0.         0.2794345\n",
      "  0.34076783 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.34076783 0.         0.         0.\n",
      "  0.2359178  0.         0.         0.         0.         0.34076783\n",
      "  0.34076783 0.         0.         0.         0.         0.17458447\n",
      "  0.17458447 0.         0.         0.2794345  0.         0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.1638043  0.1638043  0.1638043  0.         0.         0.\n",
      "  0.1638043  0.1638043  0.1638043  0.1638043  0.1638043  0.1638043\n",
      "  0.         0.0971784  0.1638043  0.1638043  0.1638043  0.1638043\n",
      "  0.         0.         0.3276086  0.1638043  0.1638043  0.1638043\n",
      "  0.1638043  0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.1638043  0.1638043\n",
      "  0.1638043  0.1638043  0.         0.1638043  0.1638043  0.1638043\n",
      "  0.2268075  0.1638043  0.1638043  0.1638043  0.1638043  0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.1638043\n",
      "  0.1638043  0.1638043  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3))\n",
    "\n",
    "small_example_docs = ['this is a document', 'this is another document', 'this is the third document', 'this is yet another doc', 'this is the fifth one','a document without much information information provided about the content despite the excessive length']\n",
    "\n",
    "X_word_features = vectorizer.fit_transform(small_example_docs)\n",
    "X_tfidf_features = tfidf_vectorizer.fit_transform(small_example_docs)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "print(tfidf_vectorizer.get_feature_names_out())\n",
    "print(X_word_features.toarray())\n",
    "print(X_tfidf_features.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2629f624-b895-4887-829c-fbbc0677238a",
   "metadata": {},
   "source": [
    "**Now let us look at how we can remove stop words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0f6e50bb-5248-45df-8e33-e08d6879623b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\z72w146\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\z72w146\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\z72w146\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\z72w146\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\z72w146\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\z72w146\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2ed0736-4986-45e9-95c4-6dfb0dff4d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #NLTK (Natural Language Toolkit)\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a46274-9b39-419b-b67f-059d730b7219",
   "metadata": {},
   "source": [
    "**Download the stopwords if you have not done already**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e85daba6-1b69-45f8-95fd-057ac4857123",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\z72w146\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbfa2dee-157c-465a-b0b8-8458ffe68e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"he's\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa22a55-8b08-40b6-a65e-b91ec6e1c310",
   "metadata": {},
   "source": [
    "**Now let's vectorize with stopwords and n-gram**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f60993ad-d93e-481f-8d30-ab46c8efd63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizers (with stopwords and n-gram range)\n",
    "vectorizer = CountVectorizer(max_features=1000, stop_words=list(stop_words))\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000, stop_words=list(stop_words), ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afed83c-a908-45b9-9d6e-b635437d787c",
   "metadata": {},
   "source": [
    "**Transform the text data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea93011a-7e09-4c0a-a529-8d4e9857601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the text data\n",
    "X_word_features = vectorizer.fit_transform(review_df['Text'])\n",
    "X_tfidf_features = tfidf_vectorizer.fit_transform(review_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08463541-1a24-4843-adc6-db60688f5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "y_text = review_df['Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "864a418e-87dc-418b-9abf-0f26733208f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split using indices\n",
    "num_instances = X_tfidf_features.shape[0]\n",
    "X_train_indices, X_test_indices, y_train, y_test = train_test_split(\n",
    "    range(num_instances), y_text, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "X_train = X_tfidf_features[X_train_indices, :]\n",
    "X_test = X_tfidf_features[X_test_indices, :]\n",
    "\n",
    "# X_train = X_word_features[X_train_indices, :]\n",
    "# X_test = X_word_features[X_test_indices, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "39939c39-c33d-471e-8489-caf3ce90a5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6496616589850942\n"
     ]
    }
   ],
   "source": [
    "# Use Multinomial Naive Bayes (correct for TF-IDF features)\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "predictions = nb_model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6333bc41-c978-4d14-9cae-4a9337752e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591438c8-669d-4de9-a98b-ca3164c40c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
