{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b548d41-f5c0-4dbb-89fc-01a48325a5b4",
   "metadata": {},
   "source": [
    "We will learn little bit more about pandas today!\n",
    "\n",
    "Okay! Let us look at the **.loc[]** and **.iloc[]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21256eaa-67ab-41ea-9808-f4b0ca59317f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55a8b15-ac24-4304-8564-0cea272a1019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"titanic.csv\")\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc892cb5-72fb-457e-a74a-5bc9a7e9a319",
   "metadata": {},
   "source": [
    "**.loc[]** is label based indexing while **.iloc[]** is integer position-based indexing.\n",
    "\n",
    "- **.loc[]**\n",
    "    - **.loc[]** is used for selecting rows and columns by labels (names).\n",
    "    - Inclusive selection: When using slicing (:), both start and end labels are included.\n",
    "    - Works with boolean indexing.\n",
    "- **.iloc[]**\n",
    "  - Used for selecting rows and columns by their integer position.\n",
    "  - Exclusive selection: Standard Python slicing rules apply (end index is excluded).\n",
    "  - Does not work with boolean indexing or labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2add68a7-ebfd-40ed-b399-f4e7fd50421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43721fe0-d54c-469b-addc-42be6f0d96a4",
   "metadata": {},
   "source": [
    "Example with boolean indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3745805-3b97-4694-a12d-af2963a3bb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pclass'] >= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930b38bc-919f-4065-92bd-84abc85894c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pclass'] >= 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ace05d7-c62b-4fca-8e19-2690fd91227b",
   "metadata": {},
   "source": [
    "Let's look at **.iloc[]**.... Let's try to access the 0th index location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef68d920-1caa-4555-bf4f-c3249beb907c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60faf424-dfba-4871-b9ce-b2a309b5154f",
   "metadata": {},
   "source": [
    "Let's look at the difference between exclusive and inclusive range selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c13aa1-fe3e-44d8-a460-b8a9e0c2ac92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d895f39-7213-4981-b8f3-e325d1f1943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[10:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d242193-2096-40aa-9f35-929e019bd00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7904de15-7c37-447e-aaca-4802026192f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[1,3,4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573ac23-f965-4730-9cf5-86db2891b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,3,4,5,6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9060514f-87fa-4abd-87fb-38e1b8d755f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[[1,3,4,5,6], ['Name','Sex']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967a2baa-6735-4afc-b4b6-84440274bea9",
   "metadata": {},
   "source": [
    "However, this does not work with iloc, it needs column locations not column labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6be825-d406-434a-a9be-8c13793ce81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[[1,3,4,5,6], ['Name','Sex']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98108a3e-06eb-4dde-ba9b-d86284887934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[100:110, :3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac287e27-b996-406f-8172-6bc046bf6663",
   "metadata": {},
   "source": [
    "You can also update and modify certain values by using the ***=*** opperator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f87687-83e3-4c95-ad93-bf7852f0ee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054279d-9140-46c4-91c4-31eabbe06486",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Pclass'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b0095d-76ef-433f-8f52-8e52562d7f0e",
   "metadata": {},
   "source": [
    "Here we look at how we can change some specific locations of a dataframe using a combination of **.loc** and broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca79602-843e-453c-af71-0c5da4856e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pclass'] == 1, ['Cabin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec952332-64b8-497a-a1e6-dfd960b0fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pclass'] == 1, ['Cabin']] = \"rr\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b19b43-1162-4261-bb3d-218d7ecd01a2",
   "metadata": {},
   "source": [
    "Here, we changed the values of all the locations of 'Cabin' to 'rr' where the 'Pclass' value is equal to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba24e44-a3ad-43d4-8653-9951c03594bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Pclass'] == 1, ['Cabin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85aa1797-2029-4185-8364-6d3be81db7b6",
   "metadata": {},
   "source": [
    "This updates everywhere with Pclass = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750a7a14-1c14-4c16-b05a-aad79a48c126",
   "metadata": {},
   "source": [
    "##### When NOT to Use .loc and .iloc\n",
    "\n",
    "- Avoid using **.loc** when your DataFrame index is not unique or meaningful—this can lead to unexpected results.\n",
    "- Avoid using **.iloc** if you expect the index to change frequently, as positional indexing can become incorrect.\n",
    "- Avoid using **.iloc** or **.loc** with large datasets in a loop—vectorized operations are faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79d035a-cd17-4552-8d62-e94ae87844d7",
   "metadata": {},
   "source": [
    "Now let us move on how to handle missing values....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051a4880-ffe5-4543-bd60-2ec9ab967b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c12f583-9762-4991-912b-ea8b6dd8d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nunique()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f1b50b-b314-4d4c-b6d5-f985e81bf8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cabin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc2c18a-4cd5-4f5a-82c9-f67bf2002d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cdaf6a-bccf-4145-b82e-3bfdb031fbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f2ea2c-2102-4c45-9d53-99c7d4d3225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74812f7b-325b-4630-a17a-a9c1fa7406a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install missingno"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176c7288-969c-464d-9188-50ee393630e7",
   "metadata": {},
   "source": [
    "**missingno** library to **visualize** missing data in a DataFrame.\n",
    "\n",
    "The matrix function of missingno generates a visual representation of the missing values in your DataFrame. Each column in the matrix corresponds to a column in the DataFrame, and each row represents an observation (data point). Missing values are shown as vertical lines or gaps in the matrix.\n",
    "\n",
    "This helps in quickly identifying the patterns of missingness in your data and can guide you in deciding how to handle the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd367b9-91d0-41be-bbab-be9fc133ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b36f13-cb28-4a8a-ba75-71ba636f4bd0",
   "metadata": {},
   "source": [
    "The sparkline at right summarizes the general shape of the data completeness and points out the rows with the maximum and minimum nullity in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea7115-aff4-4abb-bf8d-c5a03191d6b3",
   "metadata": {},
   "source": [
    "We can also create a dendogram using missinno library. \n",
    "\n",
    "Dendogram is a tree diagram.\n",
    "\n",
    "The dendrogram in **missingno** uses a hierarchical clustering algorithm to bin variables against one another by their nullity correlation (measured in terms of binary distance). At each step of the tree the variables are split up based on which combination minimizes the distance of the remaining clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72631b6-e813-4e27-b6f2-112825a6fff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.dendrogram(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc6b37e-6f4a-48df-bd8e-02a9fbc3a062",
   "metadata": {},
   "source": [
    "The missingno correlation heatmap measures nullity correlation: how strongly the presence or absence of one variable affects the presence of another:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8e760-78d4-4f75-8ddb-72c63570910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.heatmap(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23b1f126-3538-4184-b51c-61b67eb718b5",
   "metadata": {},
   "source": [
    "Nullity correlation ranges from -1 (if one variable appears the other definitely does not) to 0 (variables appearing or not appearing have no effect on one another) to 1 (if one variable appears the other definitely also does)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d6d123-44e3-40b3-992a-a55d0339dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774667da-ee40-4295-b5fe-23981de2cf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b43f77-362e-4759-ae79-416273d9b1be",
   "metadata": {},
   "source": [
    "Okay.. Now let us look at what we can do to these missing values. \n",
    "\n",
    "Easiest thing is to drop rows that has missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144a00d4-236c-438f-a472-344ef5687d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06852150-7479-421b-8f2f-cd95dcad74f4",
   "metadata": {},
   "source": [
    "This method removes rows (be default) with missing (NaN) values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e5b96-0753-46bd-9a9d-633accccb977",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab22c29-8624-4d6f-85e8-dfc512543c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a100d09d-3839-4f67-a220-daca3495f3c1",
   "metadata": {},
   "source": [
    "Now let us look how to drop rows or columns based on the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853a1928-0194-42f4-b35a-49c9a9be088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop_rows_with_na = df.copy()\n",
    "df_drop_cols_with_na = df.copy()\n",
    "df_drop_all = df.copy()\n",
    " \n",
    "df_drop_cols_with_na.dropna(inplace=True, axis=1)\n",
    "df_drop_rows_with_na.dropna(inplace=True, axis=0)\n",
    "df_drop_all.dropna(inplace=True, how='all')\n",
    "\n",
    "df_drop_cols_with_na.info()\n",
    "df_drop_rows_with_na.info()\n",
    "df_drop_all.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93752650-3dda-4e66-b698-9ba3c9a23569",
   "metadata": {},
   "source": [
    "We can even fill the Null values with something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d47987-02f1-4374-b7c8-5dbeb6d50cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_with_mean = df.copy()\n",
    "df_fill_with_mean.head()\n",
    "df_fill_with_mean.isnull().sum()\n",
    "age_mean = df_fill_with_mean['Age'].mean()\n",
    "age_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43dffad-1862-4c0c-9b3d-e925ba9113be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_with_mean['Age na filled with mean'] = df_fill_with_mean['Age'].fillna(age_mean)\n",
    "df_fill_with_mean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea68b0e-6ab0-47c4-b321-37a0d57e18c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_with_mean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaf1ae1-705c-4e13-81ce-aac0bbd0d9cb",
   "metadata": {},
   "source": [
    "You can also use something like forward filling or backward filling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121213d6-0176-4a18-88dc-d3d82319073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_with_fbfilling = df.copy()\n",
    "df_fill_with_fbfilling['Age na filled with forward filling'] = df_fill_with_fbfilling['Age'].fillna(method= 'ffill')\n",
    "df_fill_with_fbfilling['Age na filled with backward filling'] = df_fill_with_fbfilling['Age'].fillna(method= 'bfill')\n",
    "df_fill_with_fbfilling.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7586545-a15e-4c1d-8b84-79918386f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_with_fbfilling = df.copy()\n",
    "df_fill_with_fbfilling['Age na filled with forward filling'] = df_fill_with_fbfilling['Age'].ffill()\n",
    "df_fill_with_fbfilling['Age na filled with backward filling'] = df_fill_with_fbfilling['Age'].bfill()\n",
    "df_fill_with_fbfilling.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead0163b-9719-4da5-add1-7eb56a3a85fb",
   "metadata": {},
   "source": [
    "Now let's move to categorical data.\n",
    "\n",
    "We can replace values with most frequent value. **(Mode Imputation)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644d48f9-13eb-492b-8564-0e63ed9e7173",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_categorical_data = df.copy()\n",
    "most_frequent = df_fill_categorical_data[\"Cabin\"].value_counts()\n",
    "print(most_frequent.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e440249-6627-4174-9f39-3168fc76490d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_categorical_data = df.copy()\n",
    "most_frequent = df_fill_categorical_data[\"Cabin\"].value_counts().index[0]\n",
    "most_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35088bc1-7a38-4bb4-a615-db0bff24ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fill_categorical_data['cabin na filled with most freq val'] = df_fill_categorical_data['Cabin'].fillna(most_frequent)\n",
    "df_fill_categorical_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401e7c26-d9c1-4fcf-af09-1cbbd9f7e208",
   "metadata": {},
   "source": [
    "Let's look at how we can concatenate two dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf79061-337f-4ecb-b4cd-f8b708f297b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()\n",
    "df4 = pd.concat([df2, df2])\n",
    "df4.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2588b97-f127-422d-bf05-fce9c5f92995",
   "metadata": {},
   "source": [
    "Now let's remove duplicate rows from a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d54aa4-8256-4e8f-99d1-7327e8af4094",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df4.drop_duplicates()\n",
    "# you can pass inplace = True to change the dataframe inplace\n",
    "# df4.drop_duplicates(inplace=True)\n",
    "print(df4.shape)\n",
    "df4.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a20341-1603-47e4-b64a-c019ee672102",
   "metadata": {},
   "source": [
    "#### Data analysis in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47941056-f3c1-47f3-86bc-fbd3db696ea9",
   "metadata": {},
   "source": [
    "##### Summary Operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13cd4ab-8361-4cd8-bbf1-7a0a419628f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.info()\n",
    "df2.select_dtypes(include='number').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf514a-c102-4d0c-bcc3-2b21ec6c4fb9",
   "metadata": {},
   "source": [
    "Pandas has inbuilt statistical functions as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7bcb5d-0958-4fcd-9e72-87cf9ef76051",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3d474d-2646-4e01-a710-d17d44e4530c",
   "metadata": {},
   "source": [
    "This does not work as we have non-numeric columns, so what we can do is to pick the numeric columns and calculate mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261d0dc1-fdb6-4199-94a5-98111201ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd45174-3052-43f5-8203-30f2f8897d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d1dbb8-db01-4b59-aee3-202ef916f804",
   "metadata": {},
   "source": [
    "This is a nice way to exclude set of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454214d4-ec60-4e07-b299-60670780a38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2[df2.columns.difference(['PassengerId', 'Name'])].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4ff111-730b-42d5-901f-7adb61edee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[[\"Survived\", \"Pclass\"]].mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bab1367-e6a0-4863-a705-aadf6553f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.median(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f9a4a0-ded1-4310-9409-f7251b905c45",
   "metadata": {},
   "source": [
    "Let's try to create a new column based on the existing columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f181339-1fa9-494b-b0ca-0d62ba95388d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['age_to_fare_ratio'] = df2['Age']/df2['Fare']\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a59c88-234e-4f0c-b17d-7ebc4312169b",
   "metadata": {},
   "source": [
    "Let's look at how to do value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c555841-e3a3-4025-a2fd-316e9f0e367c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [],
   "source": [
    "df2['Sex'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baafd5f7-a080-42fe-8a5c-79ae942c336c",
   "metadata": {},
   "source": [
    "Adding the normalize argument returns proportions instead of absolute counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ff5fc0-f4a2-49df-bc3b-e692bc9310f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['Sex'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c781dd-5054-43f3-85cf-2e130db30839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.value_counts(subset=['Sex', 'Embarked'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46eb20b-2a92-42a1-ba3d-7df29482ec5b",
   "metadata": {},
   "source": [
    "- It groups the DataFrame by unique combinations of Sex and Embarked values.\n",
    "\n",
    "- It counts how many times each unique combination appears.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de679066-bb0f-4bbe-a5e3-585231b33e33",
   "metadata": {},
   "source": [
    "##### Aggregating with group by in pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23107c30-6503-47a4-b55a-a99b30dd76c3",
   "metadata": {},
   "source": [
    "Here I am going to group by rows using the column **Sex** and look at aggregate values. \n",
    "\n",
    "Imagine you want to find the how many Men and Women survived in Titanic.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e4fc0b-1acc-4065-84aa-4a1e15d398fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('Sex').mean(numeric_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18250963-4a7f-40f5-aef9-e24818c72368",
   "metadata": {},
   "source": [
    "Note that you have to use an aggregate method when you use groupBy.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a3e09e-0466-427f-839d-315a90b7a505",
   "metadata": {},
   "source": [
    "Let's try to do One-hot Encoding. We will learn use pandas and scikit-learn to do this.\n",
    "So first install scikit-learn if you have not done so....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edadd1ef-215c-452a-a7d5-fc65b0ab52c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d27f52f-ce74-404c-a689-d992d11077f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_coded_data = pd.DataFrame([\n",
    "    [10, 'M', 'Good'],\n",
    "    [20, 'F', 'Nice'],\n",
    "    [15, 'F', 'Good'],\n",
    "    [25, 'M', 'Great'],\n",
    "    [30, 'F', 'Nice'],\n",
    "])\n",
    "hard_coded_data.columns=['Employee id', 'Gender', 'Remarks']\n",
    "print(hard_coded_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c6ab61-e836-4e9f-ac18-513b92225082",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_pandas = pd.get_dummies(hard_coded_data, columns=['Gender', 'Remarks'])\n",
    "df_encoded_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51c21d8-4288-4376-ad40-970fc69562a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded_pandas_first_drop = pd.get_dummies(hard_coded_data, columns=['Gender', 'Remarks'], drop_first=True)\n",
    "df_encoded_pandas_first_drop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e18faa-5667-4832-83f6-566fa9ac2d32",
   "metadata": {},
   "source": [
    "The reason that we do this is one of the columns we created by one-hot encoding can be predicted by rest of the columns. This could lead to something called multicolinearity. multicollinearity is, where one column can be perfectly predicted by the others. This can be problematic in certain models, especially linear models like regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f815b3-8c12-45c4-a646-2763fe675c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df_encoded_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13ba0e-77f7-4cd8-a10c-8ffdad96aa55",
   "metadata": {},
   "source": [
    "Let's look at how we can do this using scikit-learn.\n",
    "\n",
    "If you have not installed the scikit-learn package, now would be a good time to do so...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d530a-d085-4949-9cc0-b103348a6ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dd225-4a27-4290-95eb-de89b2241c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "categorical_columns = ['Gender', 'Remarks']\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "print(hard_coded_data[categorical_columns])\n",
    "# Fit and transform the categorical columns\n",
    "\n",
    "one_hot_encoded_sci = encoder.fit_transform(hard_coded_data[categorical_columns])\n",
    "one_hot_encoded_sci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221cd453-5d8b-4b74-bf22-1ee0b13a9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the encoded columns\n",
    "one_hot_df = pd.DataFrame(one_hot_encoded_sci, \n",
    "                          columns=encoder.get_feature_names_out(categorical_columns))\n",
    "one_hot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0127deeb-b47f-414d-8810-b9b0785d7a3c",
   "metadata": {},
   "source": [
    "Now we drop the original categorical columns and attach the new one hot encoded columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb1193d-7c32-416b-b6c8-b68119c473b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the one-hot encoded columns with the original DataFrame\n",
    "hard_coded_data_with_one_hot_encoded = pd.concat([hard_coded_data.drop(categorical_columns, axis=1), one_hot_df], axis=1)\n",
    "hard_coded_data_with_one_hot_encoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
